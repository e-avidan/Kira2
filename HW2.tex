\documentclass{article}      
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}

\begin{document}

\title{%
  236605: Assignment \#2 \\
  \large RNN for NER and LM \\
    Fall Semester '17-'18}

\author{
  Avidan, Eyal \\
  \texttt{205796469}
  \and
  Goaz, Or \\
  \texttt{307950113}
}

\maketitle

\section*{1. Softmax}
\subsection*{C. Explanation of Model Class}
dsa

\subsection*{E. Why we like \emph{TensorFlow} and its automatic differentiation}
dsa


\section*{2. Deep Networks for \textbf{NER}}
\subsection*{A. Gradients}
\subsubsection*{Output Layer}
dsa

\subsubsection*{Hidden Layer}
dsa

\subsubsection*{Words}
dsa


\subsection*{B. Gradients, with Regularization}
\subsubsection*{Output Layer}
dsa

\subsubsection*{Hidden Layer}
dsa

\subsubsection*{Words}
dsa


\subsection*{C. Results}
\subsubsection*{Test Set Labels}
dsadsa

\subsubsection*{Hyperparameter Analysis}
dsadsa



\section*{3. Recurrent Neural Networks for \emph{LM}}
\subsection*{A. Perplexity}
\subsubsection*{Deriviation from Cross-Entropy}
dsa

\subsubsection*{Minimizing Mean Cross-Entropy and Mean Perplexity}
dsa

\subsubsection*{Cross-Entropy loss and Perplexity for \textbf{Random} model predictions}
dsa


\subsection*{B. Gradients}
\subsubsection*{Output Layer}
dsa

\subsubsection*{Hidden Layer}
dsa

\subsubsection*{Input Word Representation Matrix}
dsa

\subsubsection*{Embeddings}
dsa

\subsubsection*{Previous HIdden Layer}
dsa

\subsection*{C. Gradients, Through Time}
dsa - TODO: sketch of unrolled network (3 timesteps)

\subsubsection*{Output Layer}
dsa

\subsubsection*{Hidden Layer Weight Matrix}
dsa

\subsubsection*{Input Word Representation Matrix}
dsa

\subsubsection*{Hidden Layer Bias}
dsa

\subsubsection*{Previous Word}
dsa

\subsubsection*{Previous HIdden Layer}
dsa


\subsection*{D. Asymptotic Constraints}
\subsubsection*{Feed-Forward (Single Step)}
dsa

\subsubsection*{Back Propogation (Single Step)}
dsa

\subsubsection*{Feed-Forward (Multiple Steps)}
TODO - is this necessary??? dsa

\subsubsection*{Back Propogation (Multiple Steps)}
dsa

\subsubsection*{Slowest Steps}
dsa


\subsection*{E. Results}
\subsubsection*{Test Set Results}
dsadsa

\subsubsection*{Hyperparameter Analysis}
dsadsa


\subsection*{F. \textbf{RNNLM} Generated Sentences }
dsadsa


\end{document}